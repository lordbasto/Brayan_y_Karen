
# Asistente Conversacional con Pepper usando Vosk y DeepSeek

Este proyecto consiste en la implementaciÃ³n de un asistente conversacional utilizando el robot humanoide **Pepper** junto con tecnologÃ­as de reconocimiento de voz y generaciÃ³n de lenguaje natural. Se emplea **Vosk** para transcripciÃ³n en tiempo real y **DeepSeek** para la generaciÃ³n de respuestas conversacionales. Este README describe el procedimiento completo desarrollado para abordar el reto propuesto.

---

## ğŸ¯ Objetivo del Reto

Desarrollar un sistema que permita a Pepper:
- Escuchar y transcribir lo que dice un humano.
- Enviar ese texto a un modelo conversacional (IA).
- Recibir la respuesta de la IA.
- Reproducir dicha respuesta en voz usando su sistema de sÃ­ntesis.

---

## ğŸ§  Paso a Paso

### 1. InstalaciÃ³n de Vosk y PyAudio

Se comenzÃ³ instalando las bibliotecas necesarias:

```bash
pip install vosk pyaudio
```

Luego, se descargÃ³ el modelo de Vosk en espaÃ±ol desde:

> https://alphacephei.com/vosk/models


```bash
wget https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip
unzip vosk-model-small-es-0.42.zip
```

---

### 2. Captura de Voz con PyAudio y TranscripciÃ³n con Vosk

Se desarrollÃ³ un script para capturar voz en tiempo real y transcribir el audio a texto. Esto permitiÃ³ tener el input del usuario en lenguaje natural.

**CÃ³digo clave:**
```python
from vosk import Model, KaldiRecognizer
import pyaudio

model = Model("vosk-model-small-es-0.42")
rec = KaldiRecognizer(model, 16000)
```

---

### 3. EnvÃ­o del texto a la API de DeepSeek

Una vez transcrito el texto, se enviÃ³ a la API de **DeepSeek**, un modelo LLM que responde en lenguaje natural.

**Fragmento del cÃ³digo:**

```python
import requests

url = "https://api.deepseek.com/v1/chat/completions"
headers = {"Authorization": f"Bearer {api_key}"}
data = {
  "model": "deepseek-chat",
  "messages": [
    {"role": "user", "content": texto_usuario}
  ]
}
response = requests.post(url, headers=headers, json=data)
```

---

### 4. ReproducciÃ³n de la respuesta con Pepper

Utilizando el SDK de SoftBank Robotics, se hizo que Pepper pronunciara la respuesta generada:

```python
tts = session.service("ALTextToSpeech")
tts.say(respuesta_ia)
```

---

### 5. Interfaz integrada y prueba del sistema completo

Una vez integrados todos los mÃ³dulos, se realizÃ³ una prueba completa: voz â†’ texto â†’ IA â†’ voz.



---

## ğŸ§ª Resultados

El sistema logrÃ³:

- Transcribir comandos hablados con buena precisiÃ³n.
- Obtener respuestas contextuales desde DeepSeek.
- Reproducir la respuesta en voz con Pepper exitosamente.

---

## ğŸ“ Requisitos

- Python 3.x
- LibrerÃ­as: `vosk`, `pyaudio`, `requests`, `qi`
- Robot Pepper conectado en red
- MicrÃ³fono funcional

---

## ğŸ’¬ Conclusiones

Este proyecto demuestra la posibilidad de integrar tecnologÃ­as de reconocimiento de voz, modelos LLM y robÃ³tica en un flujo coherente, accesible y Ãºtil en aplicaciones reales como asistentes conversacionales, soporte, educaciÃ³n y mÃ¡s.

---

## ğŸ‘¨â€ğŸ’» Integrantes

- Brayan Poloche  
- Karen GarcÃ­a

---

## ğŸ“‚ Archivos Adjuntos

- `Proyecto Tercer Corte` â€” Informe
- `vosk-model-small-es-0.42/` â€” Carpeta del modelo
- `README.md` â€” Este documento

---

## ğŸ¥ Video Demostrativo

Puedes ver una demostraciÃ³n en video del funcionamiento del asistente conversacional con Pepper en el siguiente enlace:

[ğŸ”— Ver en YouTube](https://youtu.be/D1sjyPCZerw)

---

## ğŸ§¾ Licencia

Proyecto acadÃ©mico y educativo. Se respetan las licencias de terceros (Vosk, DeepSeek, SoftBank Robotics).

---


